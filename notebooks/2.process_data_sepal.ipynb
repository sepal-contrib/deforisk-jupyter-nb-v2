{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b838dd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effb9c20-89fb-4287-ab3e-2ce78cfe204d",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d27ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add root to path\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from component.script.utilities.file_filter import (\n",
    "    list_files_by_extension,\n",
    "    filter_files_by_keywords,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357db97-b9e1-480e-b80d-5427b18cbae5",
   "metadata": {},
   "source": [
    "## Load project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "403d7572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gfc'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from component.script.project import load_project_config\n",
    "\n",
    "\n",
    "project_name = \"test\"\n",
    "\n",
    "params, folders = load_project_config(project_name, \"params\", \"folders\")\n",
    "\n",
    "project_name = params[\"project_name\"]\n",
    "forest_source = params[\"forest_source\"]\n",
    "tree_cover_threshold = params[\"tree_cover_threshold\"]\n",
    "years = params[\"years\"]\n",
    "\n",
    "data_raw_folder = folders[\"data_raw_folder\"]\n",
    "processed_data_folder = folders[\"processed_data_folder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d9c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_defined_epsg_code = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc599b88",
   "metadata": {},
   "source": [
    "## Describe variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede069ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_forest_loss = True\n",
    "calculate_forest_loss_stack = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39640a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_binary = [\"aoi\"]\n",
    "vector_unique_values = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57214f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_categorical_variables = [\"towns\", \"rivers\", \"roads\", \"pa\", forest_source]\n",
    "raster_continuos_variables = [\"altitude\", \"slope\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f396f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_edge = [\"forest\"] # from class 1 (forest) to 0 (non-forest)\n",
    "raster_distance = [\"rivers\", \"roads\", \"town\"] # from class 0 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ff094-9fb0-49cf-ad50-35174df271f8",
   "metadata": {},
   "source": [
    "## Calculate epsg code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from component.script.geo_utils import calculate_utm_rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc11aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_epsg = calculate_utm_rioxarray(\n",
    "    str(data_raw_folder) + \"/\" + project_name + \"_subj.tif\"\n",
    ")\n",
    "calculated_epsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3641dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_defined_epsg_code is None:\n",
    "    epsg_code = calculated_epsg\n",
    "elif user_defined_epsg_code is not None:\n",
    "    epsg_code = user_defined_epsg_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f4563-f021-461a-87a8-561e28473b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsg_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae0c73",
   "metadata": {},
   "source": [
    "## Define base raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ae0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base raster to allign all the others to\n",
    "base_file_raster = str(data_raw_folder) + \"/\" + project_name + \"_subj.tif\"\n",
    "base_file_raster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa982f6a",
   "metadata": {},
   "source": [
    "## Reproject Base file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28990986-29ce-4202-9eb3-689c3238f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "\n",
    "def reproject_raster_gdal_warp(\n",
    "    input_file: str,\n",
    "    output_file: str,\n",
    "    target_epsg: str,\n",
    "    resolution: int | float = 30,\n",
    "    resampling_method: str = \"near\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reprojects a raster file to a specified EPSG code using GDAL and saves it with DEFLATE compression.\n",
    "\n",
    "    Parameters:\n",
    "    input_file (str): The path to the input raster file.\n",
    "    output_file (str): The path where the reprojected raster file will be saved.\n",
    "    target_epsg (int): The EPSG code of the target coordinate reference system.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the input dataset\n",
    "    dataset = gdal.Open(input_file)\n",
    "    if not dataset:\n",
    "        raise FileNotFoundError(f\"Input file {input_file} not found.\")\n",
    "\n",
    "    # Get projection and geotransform from the original raster\n",
    "    src_proj = dataset.GetProjection()\n",
    "\n",
    "    # Callback\n",
    "    param = gdal.WarpOptions(\n",
    "        warpOptions=[\"overwrite\"],\n",
    "        srcSRS=src_proj,\n",
    "        dstSRS=target_epsg,\n",
    "        targetAlignedPixels=True,\n",
    "        resampleAlg=resampling_method,\n",
    "        xRes=resolution,\n",
    "        yRes=resolution,\n",
    "        multithread=True,\n",
    "        creationOptions=[\n",
    "            \"COMPRESS=DEFLATE\",\n",
    "            \"PREDICTOR=2\",\n",
    "            \"BIGTIFF=YES\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Perform reprojection\n",
    "    gdal.Warp(output_file, input_file, format=\"GTiff\", options=param)\n",
    "\n",
    "    # Close datasets\n",
    "    dataset = None\n",
    "    out_dataset = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eabe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_file_raster = Path(base_file_raster)\n",
    "base_name = base_file_raster.stem\n",
    "reprojected_file_path = Path(processed_data_folder) / f\"{base_name}_reprojected.tif\"\n",
    "\n",
    "reprojected_base_file = reproject_raster_gdal_warp(\n",
    "    base_file_raster,\n",
    "    reprojected_file_path,\n",
    "    epsg_code,\n",
    "    resolution=30.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43321989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import odc.geo.xr  # do not delete this\n",
    "\n",
    "\n",
    "def get_geobox(tif_file: str = None):\n",
    "    raster_array = rioxarray.open_rasterio(\n",
    "        tif_file,\n",
    "        chunks=\"auto\",\n",
    "        cache=False,\n",
    "        lock=False,\n",
    "    )\n",
    "    return raster_array.odc.geobox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3680f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_geobox = get_geobox(reprojected_file_path)\n",
    "base_geobox\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913d8216",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Calculate Forest Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706ae76-2a0d-45bf-b4d1-88d8fabf2cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def process_forest_loss_xarray(input1_path, input2_path, output_path):\n",
    "    # Open the input rasters\n",
    "    input1 = rioxarray.open_rasterio(\n",
    "        input1_path,\n",
    "        chunks=\"auto\",\n",
    "        cache=False,\n",
    "        lock=False,\n",
    "    ).squeeze()\n",
    "    input2 = rioxarray.open_rasterio(\n",
    "        input2_path,\n",
    "        chunks=\"auto\",\n",
    "        cache=False,\n",
    "        lock=False,\n",
    "    ).squeeze()\n",
    "\n",
    "    # Check bounds properly - extract bounds tuple values\n",
    "    bounds1 = input1.rio.bounds()\n",
    "    bounds2 = input2.rio.bounds()\n",
    "\n",
    "    if not (\n",
    "        bounds1[0] <= bounds2[0]  # left\n",
    "        and bounds1[2] >= bounds2[2]  # right\n",
    "        and bounds1[3] >= bounds2[3]  # top\n",
    "        and bounds1[1] <= bounds2[1]  # bottom\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"The bounds of input1 must be equal to or larger than those of input2.\"\n",
    "        )\n",
    "\n",
    "    # Create masks for valid data\n",
    "    nodata1 = input1.rio.nodata\n",
    "    nodata2 = input2.rio.nodata\n",
    "    valid_mask = (input1 != nodata1) & (input2 != nodata2)\n",
    "\n",
    "    # Create output based on conditions using xarray operations\n",
    "    output = xr.where(\n",
    "        valid_mask & (input1 == 1) & (input2 == 0),\n",
    "        0,  # condition 0: input1 == 1 and input2 == 0\n",
    "        xr.where(\n",
    "            valid_mask & (input1 == 1) & (input2 == 1),\n",
    "            1,  # condition 1: input1 == 1 and input2 == 1\n",
    "            255,  # nodata for all other cases\n",
    "        ),\n",
    "    ).astype(\"uint8\")\n",
    "\n",
    "    # Set proper metadata\n",
    "    output.rio.write_nodata(255, inplace=True)\n",
    "    output.rio.write_crs(input1.rio.crs, inplace=True)\n",
    "    output.rio.write_transform(input1.rio.transform(), inplace=True)\n",
    "\n",
    "    output.rio.to_raster(\n",
    "        output_path,\n",
    "        driver=\"GTiff\",\n",
    "        compress=\"DEFLATE\",\n",
    "        predictor=2,\n",
    "        bigtiff=\"YES\",\n",
    "        tiled=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceba140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# List all raster files in the input folder\n",
    "forest_raster_files = list_files_by_extension(data_raw_folder, [\".tiff\", \".tif\"])\n",
    "\n",
    "\n",
    "# Define the words to filter by\n",
    "if tree_cover_threshold:\n",
    "    filter_words = [\"forest\", forest_source, str(tree_cover_threshold)]\n",
    "elif tree_cover_threshold is None:\n",
    "    filter_words = [\"forest\", forest_source]\n",
    "\n",
    "filtered_raster_files = filter_files_by_keywords(\n",
    "    forest_raster_files,\n",
    "    filter_words,\n",
    "    False,\n",
    "    [\"loss\"],\n",
    "    True,\n",
    ")\n",
    "\n",
    "\n",
    "# Function to extract the year from a filename\n",
    "def extract_year(filename):\n",
    "    match = re.search(r\"\\d{4}\", os.path.basename(filename))\n",
    "    return int(match.group()) if match else None\n",
    "\n",
    "\n",
    "# Sort the filtered raster files based on the extracted year in ascending order\n",
    "sorted_raster_files = sorted(filtered_raster_files, key=extract_year)\n",
    "\n",
    "sorted_raster_files  # Print the sorted list to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ed71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from component.script.utilities.file_helpers import generate_output_filename_loss\n",
    "\n",
    "\n",
    "if calculate_forest_loss is True:\n",
    "    forest_loss1_filename = generate_output_filename_loss(\n",
    "        sorted_raster_files[0], sorted_raster_files[1]\n",
    "    )\n",
    "    if not Path(forest_loss1_filename).exists():\n",
    "        process_forest_loss_xarray(\n",
    "            sorted_raster_files[0], sorted_raster_files[1], forest_loss1_filename\n",
    "        )\n",
    "    forest_loss2_filename = generate_output_filename_loss(\n",
    "        sorted_raster_files[0], sorted_raster_files[2]\n",
    "    )\n",
    "    if not Path(forest_loss2_filename).exists():\n",
    "        process_forest_loss_xarray(\n",
    "            sorted_raster_files[0], sorted_raster_files[2], forest_loss2_filename\n",
    "        )\n",
    "    forest_loss3_filename = generate_output_filename_loss(\n",
    "        sorted_raster_files[1], sorted_raster_files[2]\n",
    "    )\n",
    "    if not Path(forest_loss3_filename).exists():\n",
    "        process_forest_loss_xarray(\n",
    "            sorted_raster_files[1], sorted_raster_files[2], forest_loss3_filename\n",
    "        )\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "\n",
    "def generate_deforestation_raster(\n",
    "    raster1_path, raster2_path, raster3_path, output_path\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a deforestation raster from three input rasters.\n",
    "\n",
    "    Parameters:\n",
    "    - raster1_path: Path to the first raster file (period 1).\n",
    "    - raster2_path: Path to the second raster file (period 2).\n",
    "    - raster3_path: Path to the third raster file (period 3).\n",
    "    - output_path: Path to save the output raster file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the input rasters\n",
    "    with (\n",
    "        rasterio.open(raster1_path) as src1,\n",
    "        rasterio.open(raster2_path) as src2,\n",
    "        rasterio.open(raster3_path) as src3,\n",
    "    ):\n",
    "        # Read the data into numpy arrays\n",
    "        raster1 = src1.read(1)\n",
    "        raster2 = src2.read(1)\n",
    "        raster3 = src3.read(1)\n",
    "\n",
    "        # Create an output array initialized with NoData value (0)\n",
    "        output_raster = np.zeros_like(raster1, dtype=np.uint8)\n",
    "\n",
    "        # Set the values based on deforestation periods\n",
    "        output_raster[(raster1 == 1) & (raster2 == 0)] = (\n",
    "            1  # Deforestation in period 1-2\n",
    "        )\n",
    "        output_raster[(raster2 == 1) & (raster3 == 0)] = (\n",
    "            2  # Deforestation in period 2-3\n",
    "        )\n",
    "        # Set the remaining forest value only where no deforestation has been marked\n",
    "        output_raster[(output_raster == 0) & (raster3 == 1)] = (\n",
    "            3  # Remaining forest in period 3\n",
    "        )\n",
    "\n",
    "    # Define the metadata for the output raster\n",
    "    meta = src1.meta\n",
    "    meta.update({\"count\": 1, \"dtype\": np.uint8, \"nodata\": 0, \"compress\": \"deflate\"})\n",
    "\n",
    "    # Write the output raster to a file\n",
    "    with rasterio.open(output_path, \"w\", **meta) as dst:\n",
    "        dst.write(output_raster, 1)\n",
    "\n",
    "    print(f\"Done in {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d241db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from component.script.utilities.file_helpers import generate_output_filename_stack\n",
    "\n",
    "\n",
    "if calculate_forest_loss_stack is True:\n",
    "    total_forest_loss_filename = generate_output_filename_stack(\n",
    "        sorted_raster_files[0], sorted_raster_files[1], sorted_raster_files[2]\n",
    "    )\n",
    "    if not Path(total_forest_loss_filename).exists():\n",
    "        total_forest_loss = generate_deforestation_raster(\n",
    "            sorted_raster_files[0],\n",
    "            sorted_raster_files[1],\n",
    "            sorted_raster_files[2],\n",
    "            total_forest_loss_filename,\n",
    "        )\n",
    "    else:\n",
    "        print(f\"File already exists in: {total_forest_loss_filename}\")\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f9516c",
   "metadata": {},
   "source": [
    "## Reproject and Rasterize Vector Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e20fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_rasterize(\n",
    "    shapefile_path: str = None,\n",
    "    geobox=None,\n",
    "    crs=None,\n",
    "    output_path: str = None,\n",
    "    mode: str = \"binary\",\n",
    "    **rasterio_kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Rasterizes a vector shapefile into a raster array.\n",
    "\n",
    "    This function provides unified functionality for both binary and unique ID rasterization.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shapefile_path : str\n",
    "        Path to the input shapefile containing vector data.\n",
    "    geobox : odc.geo.geobox.GeoBox\n",
    "        The spatial template defining the shape, coordinates, dimensions, and transform\n",
    "        of the output raster.\n",
    "    crs : str or CRS object, optional\n",
    "        If ``geobox``'s coordinate reference system (CRS) cannot be\n",
    "        determined, provide a CRS using this parameter.\n",
    "        (e.g. 'EPSG:3577').\n",
    "    output_path : string, optional\n",
    "        Provide an optional string file path to export the rasterized\n",
    "        data as a GeoTIFF file.\n",
    "    mode : str, optional\n",
    "        Rasterization mode: 'binary' or 'unique'.\n",
    "        - 'binary': Creates a boolean raster with 1s and 0s (default)\n",
    "        - 'unique': Creates a raster with unique integer IDs for each feature\n",
    "    **rasterio_kwargs :\n",
    "        A set of keyword arguments to ``rasterio.features.rasterize``.\n",
    "        Can include: 'all_touched', 'merge_alg', 'dtype'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    da_rasterized : xarray.DataArray\n",
    "        The rasterized vector data.\n",
    "    \"\"\"\n",
    "\n",
    "    import geopandas as gpd\n",
    "    import rasterio\n",
    "    from odc.geo import xr\n",
    "\n",
    "    # Read the shapefile\n",
    "    gdf = gpd.read_file(filename=shapefile_path, engine=\"fiona\")\n",
    "\n",
    "    # Reproject vector data to raster's CRS\n",
    "    gdf_reproj = gdf.to_crs(crs=geobox.crs)\n",
    "\n",
    "    # Handle different modes\n",
    "    if mode == \"binary\":\n",
    "        # Binary mode: rasterize into a boolean array with 1s and 0s\n",
    "        shapes = gdf_reproj.geometry\n",
    "        values = [1] * len(gdf_reproj)  # All features set to 1\n",
    "        shapes_and_values = list(zip(shapes, values))\n",
    "\n",
    "    elif mode == \"unique\":\n",
    "        # Unique ID mode: rasterize using unique integer IDs for each feature\n",
    "        shapes = gdf_reproj.geometry\n",
    "        # Create unique integer IDs starting from 1\n",
    "        values = list(range(1, len(gdf_reproj) + 1))\n",
    "        shapes_and_values = list(zip(shapes, values))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be either 'binary' or 'unique'\")\n",
    "\n",
    "    # Rasterize shapes into a numpy array\n",
    "    im = rasterio.features.rasterize(\n",
    "        shapes=shapes_and_values if mode == \"unique\" else shapes,\n",
    "        out_shape=geobox.shape,\n",
    "        transform=geobox.transform,\n",
    "        dtype=\"uint8\",\n",
    "        **rasterio_kwargs,\n",
    "    )\n",
    "\n",
    "    # Convert numpy array to a full xarray.DataArray\n",
    "    # and set array name if supplied\n",
    "    da_rasterized = xr.wrap_xr(im=im, gbox=geobox)\n",
    "\n",
    "    da_rasterized.rio.to_raster(\n",
    "        output_path,\n",
    "        driver=\"GTiff\",\n",
    "        compress=\"DEFLATE\",\n",
    "        predictor=2,\n",
    "        bigtiff=\"YES\",\n",
    "        tiled=True,\n",
    "    )\n",
    "\n",
    "    # Explicitly close references â€“ not strictly required but tidy.\n",
    "    del im\n",
    "    del da_rasterized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb858cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from component.script.geo_utils import reproject_shapefile\n",
    "\n",
    "\n",
    "def rasterize_shp_files(input_folder, output_folder, geobox):\n",
    "    \"\"\"\n",
    "    Process .shp files by generating corresponding .tif filenames and calling rasterize_vectors.\n",
    "\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing .shp files.\n",
    "    output_folder (str): The path to the folder where .tif files will be saved.\n",
    "    geobox (int): The EPSG code of the target coordinate reference system.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Processing vector data...\")\n",
    "    shp_files = list_files_by_extension(input_folder, [\".shp\"])\n",
    "\n",
    "    print(f\"There's {len(shp_files)} shape files...\")\n",
    "\n",
    "    if vector_binary is not None and len(vector_binary) > 0:\n",
    "        shp_files_binary = filter_files_by_keywords(shp_files, vector_binary)\n",
    "\n",
    "        for shp_file in shp_files_binary:\n",
    "            # Extract the base name of the file without extension\n",
    "            base_name = os.path.splitext(os.path.basename(shp_file))[0]\n",
    "            # Create the new .tif filename\n",
    "            tif_filename = f\"{base_name}_reprojected.tif\"\n",
    "            tif_path = os.path.join(output_folder, tif_filename)\n",
    "            # Call rasterize_vectors with the original and new filenames\n",
    "            xr_rasterize(\n",
    "                shapefile_path=shp_file,\n",
    "                geobox=geobox,\n",
    "                output_path=tif_path,\n",
    "                mode=\"binary\",\n",
    "            )\n",
    "\n",
    "    if vector_unique_values is not None and len(vector_unique_values) > 0:\n",
    "        shp_files_unique = filter_files_by_keywords(shp_files, vector_unique_values)\n",
    "\n",
    "        for shp_file in shp_files_unique:\n",
    "            # Extract the base name of the file without extension\n",
    "            base_name = os.path.splitext(os.path.basename(shp_file))[0]\n",
    "            # Create the new .tif filename\n",
    "            tif_filename = f\"{base_name}_reprojected.tif\"\n",
    "            tif_path = os.path.join(output_folder, tif_filename)\n",
    "            # Call rasterize_vectors with the original and new filenames\n",
    "            xr_rasterize(\n",
    "                shapefile_path=shp_file,\n",
    "                geobox=geobox,\n",
    "                output_path=tif_path,\n",
    "                mode=\"unique\",\n",
    "            )\n",
    "\n",
    "    shp_files_aoi = filter_files_by_keywords(shp_files, [\"aoi\"])\n",
    "\n",
    "    for shp_file in shp_files_aoi:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(shp_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        vector_filename = f\"{base_name}_reprojected.shp\"\n",
    "        aoi_vector_reprojected = os.path.join(output_folder, vector_filename)\n",
    "        reproject_shapefile(\n",
    "            shp_file,\n",
    "            aoi_vector_reprojected,\n",
    "            geobox.crs.to_epsg(),\n",
    "        )\n",
    "\n",
    "    \n",
    "    print(\"Vector processing done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac2c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterize_shp_files(data_raw_folder, processed_data_folder, base_geobox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eec285-447d-48f4-a75c-79d7657cc413",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Reproject Raster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3301e1eb-4f85-4db1-a1bd-fa0b8a8d841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_tiff_files_near(input_folder, tif_folder, target_epsg):\n",
    "    \"\"\"\n",
    "    Reproject .tif files based on data type\n",
    "\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing .shp files.\n",
    "    tif_folder (str): The path to the folder where .tif files will be saved.\n",
    "    target_epsg (int): The EPSG code of the target coordinate reference system.\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Processing...\")\n",
    "    raster_files = list_files_by_extension(input_folder, [\".tiff\", \".tif\"])\n",
    "\n",
    "    # Define the words to filter by\n",
    "    filter_words = raster_categorical_variables\n",
    "\n",
    "    # Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "    filtered_raster_files = [\n",
    "        file\n",
    "        for file in raster_files\n",
    "        if any(word in os.path.basename(file).lower() for word in filter_words)\n",
    "    ]\n",
    "    for raster_file in filtered_raster_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(raster_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}_reprojected.tif\"\n",
    "        tif_path = os.path.join(tif_folder, tif_filename)\n",
    "        # Call rasterize_vectors with the original and new filenames\n",
    "        reproject_raster_gdal_warp(\n",
    "            raster_file,\n",
    "            tif_path,\n",
    "            target_epsg,\n",
    "            # resolution=30.0,\n",
    "        )\n",
    "\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12022a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_tiff_files_bilinear(input_folder, tif_folder, target_epsg):\n",
    "    \"\"\"\n",
    "    Reproject .tif files based on data type.\n",
    "\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing .shp files.\n",
    "    tif_folder (str): The path to the folder where .tif files will be saved.\n",
    "    target_epsg (int): The EPSG code of the target coordinate reference system.\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Processing...\")\n",
    "\n",
    "    raster_files = list_files_by_extension(input_folder, [\".tiff\", \".tif\"])\n",
    "    # Define the words to filter by\n",
    "    filter_words = raster_continuos_variables\n",
    "\n",
    "    # Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "    filtered_raster_files = [\n",
    "        file\n",
    "        for file in raster_files\n",
    "        if any(word in os.path.basename(file).lower() for word in filter_words)\n",
    "    ]\n",
    "    for raster_file in filtered_raster_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(raster_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}_reprojected.tif\"\n",
    "        tif_path = os.path.join(tif_folder, tif_filename)\n",
    "        # Call rasterize_vectors with the original and new filenames\n",
    "        reproject_raster_gdal_warp(\n",
    "            raster_file,\n",
    "            tif_path,\n",
    "            target_epsg,\n",
    "            resampling_method=\"bilinear\",\n",
    "            # resolution=30.0,\n",
    "        )\n",
    "\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb682a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproject_tiff_files_near(data_raw_folder, processed_data_folder, epsg_code) # for categorical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3d779-dc25-4656-9867-6cb80311e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproject_tiff_files_bilinear(data_raw_folder, processed_data_folder, epsg_code) # for continuous\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be5896b-e3cc-4d9d-8ced-723800b4cb79",
   "metadata": {},
   "source": [
    "## Calculate distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1182749f-474c-49a3-be6d-38bcb66c130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_edge_gdal_no_mask(\n",
    "    input_file,\n",
    "    dist_file,\n",
    "    values=0,\n",
    "    nodata=0,\n",
    "    max_distance_value=4294967295,\n",
    "    input_nodata=True,\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"Computes the shortest distance to given pixel values in a raster,\n",
    "    while preserving the original nodata mask in the output.\"\"\"\n",
    "\n",
    "    # Read input file\n",
    "    src_ds = gdal.Open(input_file)\n",
    "    srcband = src_ds.GetRasterBand(1)\n",
    "\n",
    "    # Create raster of distance\n",
    "    drv = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst_ds = drv.Create(\n",
    "        dist_file,\n",
    "        src_ds.RasterXSize,\n",
    "        src_ds.RasterYSize,\n",
    "        1,\n",
    "        gdal.GDT_UInt32,\n",
    "        [\"COMPRESS=DEFLATE\", \"PREDICTOR=2\", \"BIGTIFF=YES\"],\n",
    "    )\n",
    "    dst_ds.SetGeoTransform(src_ds.GetGeoTransform())\n",
    "    dst_ds.SetProjection(src_ds.GetProjection())\n",
    "    dstband = dst_ds.GetRasterBand(1)\n",
    "\n",
    "    # Use_input_nodata\n",
    "    ui_nodata = \"YES\" if input_nodata else \"NO\"\n",
    "\n",
    "    # Compute distance\n",
    "    val = \"VALUES=\" + str(values)\n",
    "    use_input_nodata = \"USE_INPUT_NODATA=\" + ui_nodata\n",
    "    max_distance = \"MAXDIST=\" + str(max_distance_value)\n",
    "    distance_nodata = \"NODATA=\" + str(nodata)\n",
    "    cb = gdal.TermProgress_nocb if verbose else 0\n",
    "    gdal.ComputeProximity(\n",
    "        srcband,\n",
    "        dstband,\n",
    "        [val, use_input_nodata, max_distance, distance_nodata, \"DISTUNITS=GEO\"],\n",
    "        callback=cb,\n",
    "    )\n",
    "\n",
    "    # Set nodata value\n",
    "    dstband.SetNoDataValue(max_distance_value)\n",
    "\n",
    "    # Flush to disk\n",
    "    dstband.FlushCache()\n",
    "    dst_ds.FlushCache()\n",
    "\n",
    "    # Clean up\n",
    "    srcband = None\n",
    "    dstband = None\n",
    "    del src_ds, dst_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e55afe4-d253-4154-9222-925ec1bd4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edge_tif_files(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Process .tif files by generating corresponding .tif filenames and calling compute_proximity.\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing tif files.\n",
    "    output_folder (str): The path to the folder where .tif files will be saved.\n",
    "    \"\"\"\n",
    "    # List all raster files in the input folder\n",
    "    raster_files = list_files_by_extension(input_folder, [\".tiff\", \".tif\"])\n",
    "\n",
    "    # Define the words to filter by\n",
    "    filter_words = [\"forest\", \"reprojected\", forest_source]\n",
    "\n",
    "    # Define the words to exclude from the filtered files\n",
    "    exclude_words = [\"loss\"]\n",
    "\n",
    "    # Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "    filtered_raster_files = [\n",
    "        file\n",
    "        for file in raster_files\n",
    "        if all(word in os.path.basename(file).lower() for word in filter_words)\n",
    "        and not any(\n",
    "            exclude_word in os.path.basename(file).lower()\n",
    "            for exclude_word in exclude_words\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Process each filtered raster file\n",
    "    for raster_file in filtered_raster_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(raster_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}_edge.tif\"\n",
    "        tif_path = os.path.join(output_folder, tif_filename)\n",
    "        # Call compute_proximity with the original and new filenames\n",
    "        distance_to_edge_gdal_no_mask(raster_file, tif_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee1c7c-3c24-44aa-8a9c-e2980627a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_tif_files(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Process .tif files by generating corresponding .tif filenames and calling compute_proximity.\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing tif files.\n",
    "    output_folder (str): The path to the folder where .tif files will be saved.\n",
    "    \"\"\"\n",
    "    # List all raster files in the input folder\n",
    "    raster_files = list_files_by_extension(input_folder, [\".tiff\", \".tif\"])\n",
    "\n",
    "    # Define the words to filter by\n",
    "    filter_words = raster_distance\n",
    "\n",
    "    # Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "    filtered_raster_files = [\n",
    "        file\n",
    "        for file in raster_files\n",
    "        if any(word in os.path.basename(file).lower() for word in filter_words)\n",
    "    ]\n",
    "\n",
    "    # Process each filtered raster file\n",
    "    for raster_file in filtered_raster_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(raster_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}_distance.tif\"\n",
    "        tif_path = os.path.join(output_folder, tif_filename)\n",
    "        # Call compute_proximity with the original and new filenames\n",
    "        distance_to_edge_gdal_no_mask(raster_file, tif_path, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb5f41-2836-465c-9321-5291564843db",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_edge_tif_files(processed_data_folder, processed_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f133c-b57a-46dc-a5c9-728d440da939",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_distance_tif_files(processed_data_folder, processed_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc568012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'variables': ['altitude',\n",
       "  'forest_gfc_10',\n",
       "  'pa',\n",
       "  'rivers',\n",
       "  'roads',\n",
       "  'slope',\n",
       "  'subj',\n",
       "  'towns'],\n",
       " 'temporal_variables': ['forest_gfc_10', 'towns'],\n",
       " 'non_temporal_variables': ['altitude',\n",
       "  'pa',\n",
       "  'rivers',\n",
       "  'roads',\n",
       "  'slope',\n",
       "  'subj'],\n",
       " 'years': [2015, 2020, 2024],\n",
       " 'by_variable': {'slope': {'years': [], 'temporal': False, 'modifiers': []},\n",
       "  'rivers': {'years': [], 'temporal': False, 'modifiers': []},\n",
       "  'forest_gfc_10': {'years': [2015, 2020, 2024],\n",
       "   'temporal': True,\n",
       "   'modifiers': []},\n",
       "  'altitude': {'years': [], 'temporal': False, 'modifiers': []},\n",
       "  'towns': {'years': [2015, 2020], 'temporal': True, 'modifiers': []},\n",
       "  'subj': {'years': [], 'temporal': False, 'modifiers': []},\n",
       "  'roads': {'years': [], 'temporal': False, 'modifiers': []},\n",
       "  'pa': {'years': [], 'temporal': False, 'modifiers': []}}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from component.script.create_periods import scan_raster_variables\n",
    "\n",
    "\n",
    "scan_raster_variables(folders[\"data_raw_folder\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deforisk-jupyter-nb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
