{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838dd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effb9c20-89fb-4287-ab3e-2ce78cfe204d",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d27ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add root to path\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from component.script.utilities.file_filter import (\n",
    "    list_files_by_extension,\n",
    "    filter_files_by_keywords,\n",
    "    filter_files_by_keywords_strict,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc73c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import LocalCluster, Client\n",
    "\n",
    "cluster = LocalCluster(n_workers=4, threads_per_worker=1, memory_limit=\"4e9\")\n",
    "gdal_client = Client(cluster)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357db97-b9e1-480e-b80d-5427b18cbae5",
   "metadata": {},
   "source": [
    "## Set user parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05852c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d9c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_defined_epsg_code = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc599b88",
   "metadata": {},
   "source": [
    "## Describe variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc31df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "years: list[int] = [2013, 2018, 2023]\n",
    "forest_source: Literal[\"gfc\", \"tmf\"] = \"gfc\"\n",
    "tree_cover_threshold: int = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede069ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_forest_loss = True\n",
    "calculate_forest_loss_stack = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39640a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_binary = [\"aoi\"]\n",
    "vector_unique_values = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57214f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_categorical_variables = [\n",
    "    \"towns\",\n",
    "    \"rivers\",\n",
    "    \"roads\",\n",
    "    \"pa\",\n",
    "    \"forest\",\n",
    "    \"deforestation\",\n",
    "    \"defostack\",\n",
    "    \"subj\",\n",
    "]\n",
    "raster_continuos_variables = [\"altitude\", \"slope\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f396f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_edge = [\"forest\"]  # from class 1 (forest) to 0 (non-forest)\n",
    "calculate_distance = [\"rivers\", \"roads\", \"towns\", \"deforestation\"]  # from class 0 to 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb4087f",
   "metadata": {},
   "source": [
    "## Connect folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder: Path = Path.cwd().parent\n",
    "downloads_folder: Path = root_folder / \"data\"\n",
    "downloads_folder.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904ee2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder = downloads_folder / project_name\n",
    "project_folder.mkdir(parents=True, exist_ok=True)\n",
    "data_raw_folder = project_folder / \"data_raw\"\n",
    "data_raw_folder.mkdir(parents=True, exist_ok=True)\n",
    "processed_data_folder = project_folder / \"data\"\n",
    "processed_data_folder.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ff094-9fb0-49cf-ad50-35174df271f8",
   "metadata": {},
   "source": [
    "## Calculate epsg code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from component.script.geo_utils import calculate_utm_rioxarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc11aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_epsg = calculate_utm_rioxarray(\n",
    "    str(data_raw_folder) + \"/\" + project_name + \"_pa.tif\"\n",
    ")\n",
    "calculated_epsg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3641dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_defined_epsg_code is None:\n",
    "    epsg_code = calculated_epsg\n",
    "elif user_defined_epsg_code is not None:\n",
    "    epsg_code = user_defined_epsg_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f4563-f021-461a-87a8-561e28473b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsg_code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae0c73",
   "metadata": {},
   "source": [
    "## Define base raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0ae0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base raster to allign all the others to\n",
    "base_file_raster = str(data_raw_folder) + \"/\" + project_name + \"_pa.tif\"\n",
    "base_file_raster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa982f6a",
   "metadata": {},
   "source": [
    "## Reproject Base file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28990986-29ce-4202-9eb3-689c3238f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "\n",
    "\n",
    "def reproject_raster_gdal_warp(\n",
    "    input_file: str,\n",
    "    output_file: str,\n",
    "    target_epsg: str,\n",
    "    resolution: int | float = 30,\n",
    "    resampling_method: str = \"near\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reprojects a raster file to a specified EPSG code using GDAL and saves it with DEFLATE compression.\n",
    "\n",
    "    Parameters:\n",
    "    input_file (str): The path to the input raster file.\n",
    "    output_file (str): The path where the reprojected raster file will be saved.\n",
    "    target_epsg (int): The EPSG code of the target coordinate reference system.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the input dataset\n",
    "    dataset = gdal.Open(input_file)\n",
    "    if not dataset:\n",
    "        raise FileNotFoundError(f\"Input file {input_file} not found.\")\n",
    "\n",
    "    # Get projection and geotransform from the original raster\n",
    "    src_proj = dataset.GetProjection()\n",
    "\n",
    "    # Callback\n",
    "    param = gdal.WarpOptions(\n",
    "        warpOptions=[\"overwrite\"],\n",
    "        srcSRS=src_proj,\n",
    "        dstSRS=target_epsg,\n",
    "        targetAlignedPixels=True,\n",
    "        resampleAlg=resampling_method,\n",
    "        xRes=resolution,\n",
    "        yRes=resolution,\n",
    "        multithread=True,\n",
    "        creationOptions=[\n",
    "            \"COMPRESS=DEFLATE\",\n",
    "            \"PREDICTOR=2\",\n",
    "            \"BIGTIFF=YES\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Perform reprojection\n",
    "    gdal.Warp(output_file, input_file, format=\"GTiff\", options=param)\n",
    "\n",
    "    # Close datasets\n",
    "    dataset = None\n",
    "    out_dataset = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eabe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_file_raster = Path(base_file_raster)\n",
    "base_name = base_file_raster.stem\n",
    "reprojected_file_path = Path(processed_data_folder) / f\"{base_name}_reprojected.tif\"\n",
    "\n",
    "reprojected_base_file = reproject_raster_gdal_warp(\n",
    "    base_file_raster,\n",
    "    reprojected_file_path,\n",
    "    epsg_code,\n",
    "    resolution=30.0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43321989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import odc.geo.xr  # do not delete this\n",
    "\n",
    "\n",
    "def get_geobox(tif_file: str = None):\n",
    "    raster_array = rioxarray.open_rasterio(\n",
    "        tif_file,\n",
    "        chunks=\"auto\",\n",
    "        cache=False,\n",
    "        lock=False,\n",
    "    )\n",
    "    return raster_array.odc.geobox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3680f43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_geobox = get_geobox(reprojected_file_path)\n",
    "base_geobox\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913d8216",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Calculate Forest Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706ae76-2a0d-45bf-b4d1-88d8fabf2cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def process_forest_loss_xarray(input1_path, input2_path, output_path):\n",
    "    # Open the input rasters\n",
    "    input1 = rioxarray.open_rasterio(\n",
    "        input1_path,\n",
    "        chunks=\"auto\",\n",
    "        cache=False,\n",
    "        lock=False,\n",
    "    ).squeeze()\n",
    "    input2 = rioxarray.open_rasterio(\n",
    "        input2_path,\n",
    "        chunks=\"auto\",\n",
    "        cache=False,\n",
    "        lock=False,\n",
    "    ).squeeze()\n",
    "\n",
    "    # Check bounds properly - extract bounds tuple values\n",
    "    bounds1 = input1.rio.bounds()\n",
    "    bounds2 = input2.rio.bounds()\n",
    "\n",
    "    if not (\n",
    "        bounds1[0] <= bounds2[0]  # left\n",
    "        and bounds1[2] >= bounds2[2]  # right\n",
    "        and bounds1[3] >= bounds2[3]  # top\n",
    "        and bounds1[1] <= bounds2[1]  # bottom\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"The bounds of input1 must be equal to or larger than those of input2.\"\n",
    "        )\n",
    "\n",
    "    # Create masks for valid data\n",
    "    nodata1 = input1.rio.nodata\n",
    "    nodata2 = input2.rio.nodata\n",
    "    valid_mask = (input1 != nodata1) & (input2 != nodata2)\n",
    "\n",
    "    # Create output based on conditions using xarray operations\n",
    "    output = xr.where(\n",
    "        valid_mask & (input1 == 1) & (input2 == 0),\n",
    "        0,  # condition 0: input1 == 1 and input2 == 0\n",
    "        xr.where(\n",
    "            valid_mask & (input1 == 1) & (input2 == 1),\n",
    "            1,  # condition 1: input1 == 1 and input2 == 1\n",
    "            255,  # nodata for all other cases\n",
    "        ),\n",
    "    ).astype(\"uint8\")\n",
    "\n",
    "    # Set proper metadata\n",
    "    output.rio.write_nodata(255, inplace=True)\n",
    "    output.rio.write_crs(input1.rio.crs, inplace=True)\n",
    "    output.rio.write_transform(input1.rio.transform(), inplace=True)\n",
    "\n",
    "    output.rio.to_raster(\n",
    "        output_path,\n",
    "        driver=\"GTiff\",\n",
    "        compress=\"DEFLATE\",\n",
    "        predictor=2,\n",
    "        bigtiff=\"YES\",\n",
    "        tiled=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceba140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# List all raster files in the input folder\n",
    "forest_raster_files = list_files_by_extension(data_raw_folder, [\".tiff\", \".tif\"])\n",
    "\n",
    "\n",
    "# Define the words to filter by\n",
    "if tree_cover_threshold:\n",
    "    filter_words = [\"forest\", forest_source, str(tree_cover_threshold)]\n",
    "elif tree_cover_threshold is None:\n",
    "    filter_words = [\"forest\", forest_source]\n",
    "\n",
    "filtered_raster_files = filter_files_by_keywords(\n",
    "    forest_raster_files,\n",
    "    filter_words,\n",
    "    False,\n",
    "    [\"deforestation\"],\n",
    "    True,\n",
    ")\n",
    "\n",
    "\n",
    "# Function to extract the year from a filename\n",
    "def extract_year(filename):\n",
    "    match = re.search(r\"\\d{4}\", os.path.basename(filename))\n",
    "    return int(match.group()) if match else None\n",
    "\n",
    "\n",
    "# Sort the filtered raster files based on the extracted year in ascending order\n",
    "sorted_raster_files = sorted(filtered_raster_files, key=extract_year)\n",
    "\n",
    "sorted_raster_files  # Print the sorted list to verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ed71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from component.script.utilities.file_helpers import generate_output_filename_change\n",
    "\n",
    "\n",
    "if calculate_forest_loss is True:\n",
    "    forest_loss1_filename = generate_output_filename_change(\n",
    "        sorted_raster_files[0], sorted_raster_files[1], \"deforestation\"\n",
    "    )\n",
    "    if not Path(forest_loss1_filename).exists():\n",
    "        process_forest_loss_xarray(\n",
    "            sorted_raster_files[0], sorted_raster_files[1], forest_loss1_filename\n",
    "        )\n",
    "    forest_loss2_filename = generate_output_filename_change(\n",
    "        sorted_raster_files[0], sorted_raster_files[2], \"deforestation\"\n",
    "    )\n",
    "    if not Path(forest_loss2_filename).exists():\n",
    "        process_forest_loss_xarray(\n",
    "            sorted_raster_files[0], sorted_raster_files[2], forest_loss2_filename\n",
    "        )\n",
    "    forest_loss3_filename = generate_output_filename_change(\n",
    "        sorted_raster_files[1], sorted_raster_files[2], \"deforestation\"\n",
    "    )\n",
    "    if not Path(forest_loss3_filename).exists():\n",
    "        process_forest_loss_xarray(\n",
    "            sorted_raster_files[1], sorted_raster_files[2], forest_loss3_filename\n",
    "        )\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_deforestation_raster_xarray(\n",
    "    raster1_path, raster2_path, raster3_path, output_path\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a deforestation raster from three input rasters using xarray/rioxarray\n",
    "    with vectorized operations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the input rasters with chunking for memory efficiency\n",
    "    with (\n",
    "        rioxarray.open_rasterio(\n",
    "            raster1_path,\n",
    "            chunks=\"auto\",\n",
    "            cache=False,\n",
    "            lock=False,\n",
    "        ).squeeze() as raster1,\n",
    "        rioxarray.open_rasterio(\n",
    "            raster2_path,\n",
    "            chunks=\"auto\",\n",
    "            cache=False,\n",
    "            lock=False,\n",
    "        ).squeeze() as raster2,\n",
    "        rioxarray.open_rasterio(\n",
    "            raster3_path,\n",
    "            chunks=\"auto\",\n",
    "            cache=False,\n",
    "            lock=False,\n",
    "        ).squeeze() as raster3,\n",
    "    ):\n",
    "        # Check bounds properly - extract bounds tuple values\n",
    "        bounds1 = raster1.rio.bounds()\n",
    "        bounds2 = raster2.rio.bounds()\n",
    "        bounds3 = raster3.rio.bounds()\n",
    "\n",
    "        if not (\n",
    "            bounds1[0] <= bounds2[0]  # left\n",
    "            and bounds1[2] >= bounds2[2]  # right\n",
    "            and bounds1[3] >= bounds2[3]  # top\n",
    "            and bounds1[1] <= bounds2[1]  # bottom\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"The bounds of raster1 must be equal to or larger than those of raster2.\"\n",
    "            )\n",
    "\n",
    "        if not (\n",
    "            bounds1[0] <= bounds3[0]  # left\n",
    "            and bounds1[2] >= bounds3[2]  # right\n",
    "            and bounds1[3] >= bounds3[3]  # top\n",
    "            and bounds1[1] <= bounds3[1]  # bottom\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"The bounds of raster1 must be equal to or larger than those of raster3.\"\n",
    "            )\n",
    "\n",
    "        # Create output based on conditions using xarray operations\n",
    "        output = xr.full_like(raster1, 0, dtype=\"uint8\")\n",
    "\n",
    "        # Deforestation in period 1-2: raster1 == 1 and raster2 == 0\n",
    "        condition1 = (raster1 == 1) & (raster2 == 0)\n",
    "        output = output.where(~condition1, 1)\n",
    "\n",
    "        # Deforestation in period 2-3: raster2 == 1 and raster3 == 0\n",
    "        condition2 = (raster2 == 1) & (raster3 == 0)\n",
    "        output = output.where(~condition2, 2)\n",
    "\n",
    "        # Remaining forest in period 3: no deforestation and raster3 == 1\n",
    "        condition3 = (output == 0) & (raster3 == 1)\n",
    "        output = output.where(~condition3, 3)\n",
    "\n",
    "    # Set proper metadata\n",
    "    output.rio.write_nodata(0, inplace=True)\n",
    "    output.rio.write_crs(raster1.rio.crs, inplace=True)\n",
    "    output.rio.write_transform(raster1.rio.transform(), inplace=True)\n",
    "\n",
    "    # Write the output raster with optimized parameters\n",
    "    from dask.distributed import Lock\n",
    "\n",
    "    output.rio.to_raster(\n",
    "        output_path,\n",
    "        driver=\"GTiff\",\n",
    "        compress=\"DEFLATE\",\n",
    "        predictor=2,\n",
    "        bigtiff=\"YES\",\n",
    "        tiled=True,\n",
    "        lock=Lock(\"rio\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d241db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from component.script.utilities.file_helpers import generate_output_filename_stack\n",
    "\n",
    "\n",
    "if calculate_forest_loss_stack is True:\n",
    "    total_forest_loss_filename = generate_output_filename_stack(\n",
    "        sorted_raster_files[0],\n",
    "        sorted_raster_files[1],\n",
    "        sorted_raster_files[2],\n",
    "        \"defostack\",\n",
    "    )\n",
    "    if not Path(total_forest_loss_filename).exists():\n",
    "        total_forest_loss = generate_deforestation_raster_xarray(\n",
    "            sorted_raster_files[0],\n",
    "            sorted_raster_files[1],\n",
    "            sorted_raster_files[2],\n",
    "            total_forest_loss_filename,\n",
    "        )\n",
    "    else:\n",
    "        print(f\"File already exists in: {total_forest_loss_filename}\")\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f9516c",
   "metadata": {},
   "source": [
    "## Reproject and Rasterize Vector Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e20fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_rasterize(\n",
    "    shapefile_path: str = None,\n",
    "    geobox=None,\n",
    "    crs=None,\n",
    "    output_path: str = None,\n",
    "    mode: str = \"binary\",\n",
    "    **rasterio_kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Rasterizes a vector shapefile into a raster array.\n",
    "\n",
    "    This function provides unified functionality for both binary and unique ID rasterization.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shapefile_path : str\n",
    "        Path to the input shapefile containing vector data.\n",
    "    geobox : odc.geo.geobox.GeoBox\n",
    "        The spatial template defining the shape, coordinates, dimensions, and transform\n",
    "        of the output raster.\n",
    "    crs : str or CRS object, optional\n",
    "        If ``geobox``'s coordinate reference system (CRS) cannot be\n",
    "        determined, provide a CRS using this parameter.\n",
    "        (e.g. 'EPSG:3577').\n",
    "    output_path : string, optional\n",
    "        Provide an optional string file path to export the rasterized\n",
    "        data as a GeoTIFF file.\n",
    "    mode : str, optional\n",
    "        Rasterization mode: 'binary' or 'unique'.\n",
    "        - 'binary': Creates a boolean raster with 1s and 0s (default)\n",
    "        - 'unique': Creates a raster with unique integer IDs for each feature\n",
    "    **rasterio_kwargs :\n",
    "        A set of keyword arguments to ``rasterio.features.rasterize``.\n",
    "        Can include: 'all_touched', 'merge_alg', 'dtype'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    da_rasterized : xarray.DataArray\n",
    "        The rasterized vector data.\n",
    "    \"\"\"\n",
    "\n",
    "    import geopandas as gpd\n",
    "    import rasterio\n",
    "    from odc.geo import xr\n",
    "\n",
    "    # Read the shapefile\n",
    "    gdf = gpd.read_file(filename=shapefile_path, engine=\"fiona\")\n",
    "\n",
    "    # Reproject vector data to raster's CRS\n",
    "    gdf_reproj = gdf.to_crs(crs=geobox.crs)\n",
    "\n",
    "    # Handle different modes\n",
    "    if mode == \"binary\":\n",
    "        # Binary mode: rasterize into a boolean array with 1s and 0s\n",
    "        shapes = gdf_reproj.geometry\n",
    "        values = [1] * len(gdf_reproj)  # All features set to 1\n",
    "        shapes_and_values = list(zip(shapes, values))\n",
    "\n",
    "    elif mode == \"unique\":\n",
    "        # Unique ID mode: rasterize using unique integer IDs for each feature\n",
    "        shapes = gdf_reproj.geometry\n",
    "        # Create unique integer IDs starting from 1\n",
    "        values = list(range(1, len(gdf_reproj) + 1))\n",
    "        shapes_and_values = list(zip(shapes, values))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Mode must be either 'binary' or 'unique'\")\n",
    "\n",
    "    # Rasterize shapes into a numpy array\n",
    "    im = rasterio.features.rasterize(\n",
    "        shapes=shapes_and_values if mode == \"unique\" else shapes,\n",
    "        out_shape=geobox.shape,\n",
    "        transform=geobox.transform,\n",
    "        dtype=\"uint8\",\n",
    "        **rasterio_kwargs,\n",
    "    )\n",
    "\n",
    "    # Convert numpy array to a full xarray.DataArray\n",
    "    # and set array name if supplied\n",
    "    da_rasterized = xr.wrap_xr(im=im, gbox=geobox)\n",
    "\n",
    "    da_rasterized.rio.to_raster(\n",
    "        output_path,\n",
    "        driver=\"GTiff\",\n",
    "        compress=\"DEFLATE\",\n",
    "        predictor=2,\n",
    "        bigtiff=\"YES\",\n",
    "        tiled=True,\n",
    "    )\n",
    "\n",
    "    # Explicitly close references â€“ not strictly required but tidy.\n",
    "    del im\n",
    "    del da_rasterized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb858cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from component.script.geo_utils import reproject_shapefile, xr_reproject\n",
    "\n",
    "\n",
    "def rasterize_shp_files(input_folder, output_folder, geobox):\n",
    "    \"\"\"\n",
    "    Process .shp files by generating corresponding .tif filenames and calling rasterize_vectors.\n",
    "\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing .shp files.\n",
    "    output_folder (str): The path to the folder where .tif files will be saved.\n",
    "    geobox (int): The EPSG code of the target coordinate reference system.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Processing vector data...\")\n",
    "    shp_files = list_files_by_extension(input_folder, [\".shp\"])\n",
    "\n",
    "    print(f\"There's {len(shp_files)} shape files...\")\n",
    "\n",
    "    if vector_binary is not None and len(vector_binary) > 0:\n",
    "        shp_files_binary = filter_files_by_keywords(shp_files, vector_binary)\n",
    "\n",
    "        for shp_file in shp_files_binary:\n",
    "            # Extract the base name of the file without extension\n",
    "            base_name = os.path.splitext(os.path.basename(shp_file))[0]\n",
    "            # Create the new .tif filename\n",
    "            tif_filename = f\"{base_name}_reprojected.tif\"\n",
    "            tif_path = os.path.join(output_folder, tif_filename)\n",
    "            # Call rasterize_vectors with the original and new filenames\n",
    "            xr_rasterize(\n",
    "                shapefile_path=shp_file,\n",
    "                geobox=geobox,\n",
    "                output_path=tif_path,\n",
    "                mode=\"binary\",\n",
    "            )\n",
    "\n",
    "    if vector_unique_values is not None and len(vector_unique_values) > 0:\n",
    "        shp_files_unique = filter_files_by_keywords(shp_files, vector_unique_values)\n",
    "\n",
    "        for shp_file in shp_files_unique:\n",
    "            # Extract the base name of the file without extension\n",
    "            base_name = os.path.splitext(os.path.basename(shp_file))[0]\n",
    "            # Create the new .tif filename\n",
    "            tif_filename = f\"{base_name}_reprojected.tif\"\n",
    "            tif_path = os.path.join(output_folder, tif_filename)\n",
    "            # Call rasterize_vectors with the original and new filenames\n",
    "            xr_rasterize(\n",
    "                shapefile_path=shp_file,\n",
    "                geobox=geobox,\n",
    "                output_path=tif_path,\n",
    "                mode=\"unique\",\n",
    "            )\n",
    "\n",
    "    shp_files_aoi = filter_files_by_keywords(shp_files, [\"aoi\"])\n",
    "\n",
    "    for shp_file in shp_files_aoi:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(shp_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        vector_filename = f\"{base_name}_reprojected.shp\"\n",
    "        aoi_vector_reprojected = os.path.join(output_folder, vector_filename)\n",
    "        reproject_shapefile(\n",
    "            shp_file,\n",
    "            aoi_vector_reprojected,\n",
    "            geobox.crs.to_epsg(),\n",
    "        )\n",
    "\n",
    "    print(\"Vector processing done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac2c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterize_shp_files(data_raw_folder, processed_data_folder, base_geobox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eec285-447d-48f4-a75c-79d7657cc413",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Reproject Raster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bf578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from component.script.geo_utils import xr_reproject\n",
    "from component.script.xarray.dask_reproject_rio import (\n",
    "    reproject_raster_rio_with_dask,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3301e1eb-4f85-4db1-a1bd-fa0b8a8d841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_tiff_files_near(input_folder, tif_folder, geobox):\n",
    "    \"\"\"\n",
    "    Reproject .tif files based on data type\n",
    "\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing .shp files.\n",
    "    tif_folder (str): The path to the folder where .tif files will be saved.\n",
    "    target_epsg (int): The EPSG code of the target coordinate reference system.\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Processing...\")\n",
    "\n",
    "    raster_files = list_files_by_extension(input_folder, [\".tiff\", \".tif\"])\n",
    "    # Define the words to filter by\n",
    "    filter_words = raster_categorical_variables\n",
    "\n",
    "    # Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "    filtered_raster_files = [\n",
    "        file\n",
    "        for file in raster_files\n",
    "        if any(word in os.path.basename(file).lower() for word in filter_words)\n",
    "    ]\n",
    "    for raster_file in filtered_raster_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(raster_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}_reprojected.tif\"\n",
    "        tif_path = os.path.join(tif_folder, tif_filename)\n",
    "        # Call rasterize_vectors with the original and new filenames\n",
    "        if not Path(tif_path).exists():\n",
    "            reproject_raster_rio_with_dask(raster_file, geobox, \"nearest\", tif_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12022a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_tiff_files_bilinear(input_folder, tif_folder, geobox):\n",
    "    \"\"\"\n",
    "    Reproject .tif files based on data type.\n",
    "\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing .shp files.\n",
    "    tif_folder (str): The path to the folder where .tif files will be saved.\n",
    "    target_epsg (int): The EPSG code of the target coordinate reference system.\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Processing...\")\n",
    "\n",
    "    raster_files = list_files_by_extension(input_folder, [\".tiff\", \".tif\"])\n",
    "    # Define the words to filter by\n",
    "    filter_words = raster_continuos_variables\n",
    "\n",
    "    # Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "    filtered_raster_files = [\n",
    "        file\n",
    "        for file in raster_files\n",
    "        if any(word in os.path.basename(file).lower() for word in filter_words)\n",
    "    ]\n",
    "    for raster_file in filtered_raster_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(raster_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}_reprojected.tif\"\n",
    "        tif_path = os.path.join(tif_folder, tif_filename)\n",
    "        # Call rasterize_vectors with the original and new filenames\n",
    "        if not Path(tif_path).exists():\n",
    "            reproject_raster_rio_with_dask(raster_file, geobox, \"bilinear\", tif_path)\n",
    "            # xr_reproject(raster_file, geobox, \"bilinear\", tif_path)\n",
    "\n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb682a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproject_tiff_files_near(\n",
    "    data_raw_folder, processed_data_folder, base_geobox\n",
    ")  # for categorical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3d779-dc25-4656-9867-6cb80311e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproject_tiff_files_bilinear(\n",
    "    data_raw_folder, processed_data_folder, base_geobox\n",
    ")  # for continuous\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be5896b-e3cc-4d9d-8ced-723800b4cb79",
   "metadata": {},
   "source": [
    "## Calculate distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1182749f-474c-49a3-be6d-38bcb66c130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_edge_gdal_no_mask(\n",
    "    input_file,\n",
    "    dist_file,\n",
    "    values=0,\n",
    "    nodata=0,\n",
    "    max_distance_value=4294967295,\n",
    "    input_nodata=True,\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"Computes the shortest distance to given pixel values in a raster,\n",
    "    while preserving the original nodata mask in the output.\"\"\"\n",
    "\n",
    "    # Read input file\n",
    "    src_ds = gdal.Open(input_file)\n",
    "    srcband = src_ds.GetRasterBand(1)\n",
    "\n",
    "    # Create raster of distance\n",
    "    drv = gdal.GetDriverByName(\"GTiff\")\n",
    "    dst_ds = drv.Create(\n",
    "        dist_file,\n",
    "        src_ds.RasterXSize,\n",
    "        src_ds.RasterYSize,\n",
    "        1,\n",
    "        gdal.GDT_UInt32,\n",
    "        [\"COMPRESS=DEFLATE\", \"PREDICTOR=2\", \"BIGTIFF=YES\"],\n",
    "    )\n",
    "    dst_ds.SetGeoTransform(src_ds.GetGeoTransform())\n",
    "    dst_ds.SetProjection(src_ds.GetProjection())\n",
    "    dstband = dst_ds.GetRasterBand(1)\n",
    "\n",
    "    # Use_input_nodata\n",
    "    ui_nodata = \"YES\" if input_nodata else \"NO\"\n",
    "\n",
    "    # Compute distance\n",
    "    val = \"VALUES=\" + str(values)\n",
    "    use_input_nodata = \"USE_INPUT_NODATA=\" + ui_nodata\n",
    "    max_distance = \"MAXDIST=\" + str(max_distance_value)\n",
    "    distance_nodata = \"NODATA=\" + str(nodata)\n",
    "    cb = gdal.TermProgress_nocb if verbose else 0\n",
    "    gdal.ComputeProximity(\n",
    "        srcband,\n",
    "        dstband,\n",
    "        [val, use_input_nodata, max_distance, distance_nodata, \"DISTUNITS=GEO\"],\n",
    "        callback=cb,\n",
    "    )\n",
    "\n",
    "    # Set nodata value\n",
    "    dstband.SetNoDataValue(max_distance_value)\n",
    "\n",
    "    # Flush to disk\n",
    "    dstband.FlushCache()\n",
    "    dst_ds.FlushCache()\n",
    "\n",
    "    # Clean up\n",
    "    srcband = None\n",
    "    dstband = None\n",
    "    del src_ds, dst_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e55afe4-d253-4154-9222-925ec1bd4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edge_tif_files(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Process .tif files by generating corresponding .tif filenames and calling compute_proximity.\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing tif files.\n",
    "    output_folder (str): The path to the folder where .tif files will be saved.\n",
    "    \"\"\"\n",
    "    # List all raster files in the input folder\n",
    "    raster_files = list_files_by_extension(input_folder, [\".tiff\", \".tif\"])\n",
    "\n",
    "    # Define the words to filter by\n",
    "    filter_words = calculate_edge\n",
    "\n",
    "    # Define the words to exclude from the filtered files\n",
    "    exclude_words = [\"distance\", \"edge\"]\n",
    "\n",
    "    # Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "    filtered_raster_files = filter_files_by_keywords_strict(\n",
    "        raster_files, filter_words, True, exclude_words\n",
    "    )\n",
    "\n",
    "    print(f\"Processing {filtered_raster_files}\")\n",
    "\n",
    "    # Process each filtered raster file\n",
    "    for raster_file in filtered_raster_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(raster_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}_edge.tif\"\n",
    "        tif_path = os.path.join(output_folder, tif_filename)\n",
    "        # Call compute_proximity with the original and new filenames\n",
    "        distance_to_edge_gdal_no_mask(raster_file, tif_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee1c7c-3c24-44aa-8a9c-e2980627a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_tif_files(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Process .tif files by generating corresponding .tif filenames and calling compute_proximity.\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing tif files.\n",
    "    output_folder (str): The path to the folder where .tif files will be saved.\n",
    "    \"\"\"\n",
    "    # List all raster files in the input folder\n",
    "    raster_files = list_files_by_extension(input_folder, [\".tiff\", \".tif\"])\n",
    "\n",
    "    # Define the words to filter by\n",
    "    filter_words = calculate_distance\n",
    "\n",
    "    # Define the words to exclude from the filtered files\n",
    "    exclude_words = [\"distance\", \"edge\"]\n",
    "\n",
    "    # Filter the raster files based on the presence of any of the filter words in their filenames\n",
    "    filtered_raster_files = filter_files_by_keywords_strict(\n",
    "        raster_files, filter_words, True, exclude_words\n",
    "    )\n",
    "\n",
    "    print(f\"Processing {filtered_raster_files}\")\n",
    "\n",
    "    # Process each filtered raster file\n",
    "    for raster_file in filtered_raster_files:\n",
    "        # Extract the base name of the file without extension\n",
    "        base_name = os.path.splitext(os.path.basename(raster_file))[0]\n",
    "        # Create the new .tif filename\n",
    "        tif_filename = f\"{base_name}_distance.tif\"\n",
    "        tif_path = os.path.join(output_folder, tif_filename)\n",
    "        # Call compute_proximity with the original and new filenames\n",
    "        if not Path(tif_path).exists():\n",
    "            distance_to_edge_gdal_no_mask(raster_file, tif_path, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb5f41-2836-465c-9321-5291564843db",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_edge_tif_files(processed_data_folder, processed_data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f133c-b57a-46dc-a5c9-728d440da939",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_distance_tif_files(processed_data_folder, processed_data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3c8d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deforisk-jupyter-nb (3.11.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
